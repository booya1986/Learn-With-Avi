# Multi-Agent Architecture for LearnWithAvi Platform

## Executive Summary

This document defines the multi-agent orchestration system for the LearnWithAvi AI-powered interactive learning platform. The architecture consists of **one orchestrator agent** (Project Manager AI) that delegates tasks to **7 specialized sub-agents**, each with domain-specific skills and methodologies.

---

## Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ORCHESTRATOR AGENT                           ‚îÇ
‚îÇ                  "Project Manager AI"                           ‚îÇ
‚îÇ               (claude-sonnet-4-5-20251101)                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Responsibilities:                                              ‚îÇ
‚îÇ  ‚Ä¢ Task analysis and decomposition                             ‚îÇ
‚îÇ  ‚Ä¢ Agent selection and delegation                              ‚îÇ
‚îÇ  ‚Ä¢ Dependency management (sequential vs parallel)              ‚îÇ
‚îÇ  ‚Ä¢ Progress tracking and reporting                             ‚îÇ
‚îÇ  ‚Ä¢ Conflict resolution                                         ‚îÇ
‚îÇ  ‚Ä¢ Quality assurance coordination                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ                 ‚îÇ                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Frontend         ‚îÇ ‚îÇ  Backend      ‚îÇ ‚îÇ  RAG         ‚îÇ
‚îÇ  Engineer         ‚îÇ ‚îÇ  Engineer     ‚îÇ ‚îÇ  Specialist  ‚îÇ
‚îÇ  (React/Next.js)  ‚îÇ ‚îÇ  (API/DB)     ‚îÇ ‚îÇ  (Vector AI) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                 ‚îÇ                 ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  UI/UX            ‚îÇ ‚îÇ  DevOps       ‚îÇ ‚îÇ  QA          ‚îÇ
‚îÇ  Designer         ‚îÇ ‚îÇ  Engineer     ‚îÇ ‚îÇ  Engineer    ‚îÇ
‚îÇ  (Design/A11y)    ‚îÇ ‚îÇ  (Deploy/CI)  ‚îÇ ‚îÇ  (Testing)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ  Product Manager  ‚îÇ
                  ‚îÇ  (Requirements)   ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 1. Orchestrator Agent: Project Manager AI

### Configuration
```json
{
  "name": "orchestrator",
  "display_name": "Project Manager AI",
  "model": "claude-sonnet-4-5-20251101",
  "role": "Orchestrator and task coordinator",
  "description": "Analyzes user requests, decomposes complex tasks, delegates to specialized sub-agents, and coordinates their work"
}
```

### Core Responsibilities

1. **Task Analysis**
   - Parse user requests into actionable subtasks
   - Identify required expertise domains
   - Determine task dependencies
   - Estimate complexity and priority

2. **Agent Selection & Delegation**
   - Select appropriate sub-agents based on task requirements
   - Determine execution pattern:
     - **Single**: One agent handles the entire task
     - **Sequential**: Agents work in order (A ‚Üí B ‚Üí C)
     - **Parallel**: Multiple agents work simultaneously
     - **Parallel-then-Coordinate**: Parallel work followed by integration

3. **Coordination**
   - Monitor sub-agent progress
   - Handle inter-agent dependencies
   - Resolve conflicts between agents
   - Ensure code quality and consistency

4. **Communication**
   - Report progress to user
   - Provide status updates
   - Escalate blockers
   - Summarize completed work

### Delegation Rules

| Task Type | Pattern | Example Agents |
|-----------|---------|----------------|
| Add UI feature | Sequential | UI/UX Designer ‚Üí Frontend Engineer ‚Üí QA Engineer |
| Fix bug | Single | Relevant specialist (Frontend/Backend/RAG) |
| API endpoint | Sequential | Backend Engineer ‚Üí Frontend Engineer ‚Üí QA Engineer |
| Performance optimization | Parallel-then-Coordinate | Frontend + Backend + RAG Specialist |
| Deployment | Sequential | DevOps ‚Üí QA Engineer |
| New feature | Parallel-then-Coordinate | Product Manager ‚Üí (UI/UX + Frontend + Backend) ‚Üí QA |

### Decision Framework

```python
def select_agents(task: Task) -> AgentExecution:
    """Orchestrator's decision framework"""

    # Analyze task requirements
    domains = analyze_required_domains(task)
    dependencies = identify_dependencies(task)

    # Single domain ‚Üí Single agent
    if len(domains) == 1:
        return SingleAgent(domains[0])

    # Multiple independent domains ‚Üí Parallel
    if not dependencies:
        return ParallelAgents(domains)

    # Sequential dependencies ‚Üí Sequential
    if is_linear_dependency(dependencies):
        return SequentialAgents(sorted_by_dependency(domains))

    # Complex dependencies ‚Üí Parallel-then-Coordinate
    return ParallelThenCoordinate(
        parallel_phase=independent_domains,
        coordinator=select_coordinator_agent(domains)
    )
```

---

## 2. Sub-Agent Specifications

### 2.1 Frontend Engineer Agent

**Model**: `claude-sonnet-4-5` (complex UI) / `claude-haiku-4` (simple fixes)

**Domain Expertise**:
- React 19 + Next.js 16 App Router
- TypeScript 5 (strict mode)
- Tailwind CSS 4 + shadcn/ui components
- Client-side state management (Context, TanStack Query)
- React hooks and custom hook patterns
- Responsive design (mobile-first)
- Performance optimization (memoization, lazy loading)

**Specific Skills for LearnWithAvi**:
- YouTube player integration (react-youtube)
- Real-time video synchronization with transcripts
- Chapter timeline UI with hover tooltips
- Chat interface with streaming messages
- Voice UI components (recording indicators, waveforms)
- RTL (Hebrew) layout support
- Clickable timestamp links in chat messages
- Progress tracking visualizations

**Methodologies**:
1. **Component-First Development**
   - Start with UI component structure
   - Implement props interface
   - Add state management
   - Connect to APIs/hooks

2. **Testing Approach**
   - Unit tests for utility functions
   - Component tests with Testing Library
   - Visual regression tests for critical UI

3. **Performance Guidelines**
   - Use React.memo for expensive components
   - Lazy load heavy components (video player)
   - Debounce user inputs (search, chat)
   - Optimize re-renders with useCallback/useMemo

**Input/Output Contract**:
```typescript
// Input from orchestrator
interface FrontendTask {
  type: "feature" | "fix" | "refactor" | "optimize"
  component: string  // "VideoPlayer" | "ChatPanel" | etc.
  requirements: string[]
  acceptanceCriteria: string[]
  designReference?: string  // Figma link or description
}

// Output to orchestrator
interface FrontendResult {
  filesModified: string[]
  componentsCreated: string[]
  testsAdded: string[]
  performance: {
    bundleImpact: string  // "+5KB gzipped"
    renderTime: string    // "12ms average"
  }
  screenshots?: string[]
}
```

---

### 2.2 Backend Engineer Agent

**Model**: `claude-sonnet-4-5`

**Domain Expertise**:
- Node.js + TypeScript server-side development
- Next.js API Routes (App Router)
- RESTful API design
- Server-Sent Events (SSE) for streaming
- Database design (PostgreSQL + Prisma)
- Authentication (Clerk integration)
- Rate limiting and security
- Error handling and sanitization
- Environment configuration

**Specific Skills for LearnWithAvi**:
- Anthropic Claude API integration (with prompt caching)
- OpenAI API integration (embeddings, Whisper)
- ElevenLabs API integration (TTS)
- ChromaDB vector database operations
- YouTube API integration (metadata, transcripts)
- SSE streaming response handling
- API key security and sanitization
- Rate limiting per endpoint

**Methodologies**:
1. **API-First Development**
   - Define OpenAPI/type-safe contracts
   - Implement request validation (Zod schemas)
   - Add error handling with sanitization
   - Write integration tests
   - Document with JSDoc/OpenAPI

2. **Security Checklist**
   - Input validation on all endpoints
   - Rate limiting configured
   - API keys never exposed in errors
   - CORS properly configured
   - SQL injection prevention (Prisma)
   - XSS prevention (sanitize outputs)

3. **Database Design Patterns**
   - Prisma schema modeling
   - Migration strategy
   - Query optimization
   - Connection pooling
   - Transaction management

**Input/Output Contract**:
```typescript
// Input from orchestrator
interface BackendTask {
  type: "api" | "database" | "integration" | "security"
  endpoint?: string  // "/api/chat" | "/api/voice/tts"
  requirements: string[]
  schema?: object  // Zod or Prisma schema
  externalAPIs?: string[]  // ["anthropic", "openai"]
}

// Output to orchestrator
interface BackendResult {
  filesModified: string[]
  endpointsCreated: string[]
  schemasCreated: string[]
  migrationsCreated: string[]
  securityChecks: {
    inputValidation: boolean
    rateLimiting: boolean
    errorSanitization: boolean
    authentication: boolean
  }
  testCoverage: number
}
```

---

### 2.3 RAG Pipeline Specialist Agent

**Model**: `claude-sonnet-4-5`

**Domain Expertise**:
- Vector embeddings (OpenAI, Anthropic)
- Vector databases (ChromaDB, Pinecone, Weaviate)
- Semantic search algorithms
- Hybrid search (semantic + keyword)
- Retrieval evaluation (precision, recall, MRR)
- Chunking strategies (semantic, fixed-size, overlapping)
- Prompt engineering for RAG
- Context caching optimization
- Multilingual embeddings (Hebrew support)

**Specific Skills for LearnWithAvi**:
- Video transcript chunking (timestamp-aligned)
- Chapter-aware retrieval
- Clickable timestamp extraction
- Fallback to keyword search (when ChromaDB unavailable)
- Hebrew text processing
- Source citation formatting
- Relevance scoring and re-ranking
- LRU caching for embeddings

**Methodologies**:
1. **RAG Pipeline Design**
   ```
   Query ‚Üí Embedding ‚Üí Vector Search ‚Üí Re-ranking ‚Üí Context Injection ‚Üí LLM
   ```
   - Analyze query intent
   - Generate embeddings
   - Retrieve top-K chunks (K=10-20)
   - Re-rank by relevance
   - Format sources with timestamps
   - Inject into prompt with caching

2. **Evaluation Framework**
   - **Precision**: Are retrieved chunks relevant?
   - **Recall**: Are all relevant chunks retrieved?
   - **MRR** (Mean Reciprocal Rank): How high are relevant results?
   - **Latency**: Time from query to response
   - **Cost**: Embedding + LLM API costs

3. **Optimization Strategies**
   - Prompt caching (75% cost reduction)
   - Embedding caching (30% cost reduction)
   - Hybrid search fallback
   - Chunk size optimization (500-1000 tokens)
   - Overlap optimization (50-100 tokens)

**Input/Output Contract**:
```typescript
// Input from orchestrator
interface RAGTask {
  type: "optimize" | "evaluate" | "fix" | "add_data"
  pipeline: "transcript_search" | "chapter_search" | "knowledge_base"
  requirements: string[]
  evaluationMetrics?: string[]  // ["precision", "recall", "mrr"]
}

// Output to orchestrator
interface RAGResult {
  filesModified: string[]
  metricsImproved: {
    before: Record<string, number>
    after: Record<string, number>
    improvement: string  // "15% precision increase"
  }
  costImpact: {
    embeddingCost: string  // "-30% with caching"
    llmCost: string        // "-75% with prompt caching"
  }
  recommendations: string[]
}
```

---

### 2.4 UI/UX Designer Agent

**Model**: `claude-sonnet-4-5`

**Domain Expertise**:
- User interface design principles
- Accessibility (WCAG 2.1 AA compliance)
- Responsive design (mobile-first)
- Design systems (shadcn/ui, Radix UI)
- Color theory and contrast ratios
- Typography and readability
- User flow design
- Interaction patterns
- Usability testing

**Specific Skills for LearnWithAvi**:
- Three-column layout optimization
- RTL (Hebrew) design patterns
- Video player controls UX
- Chat interface design (streaming messages)
- Voice interaction UI (recording indicators)
- Progress visualization (chapter timeline)
- Dark mode design
- Mobile responsive breakpoints

**Methodologies**:
1. **Design Process**
   - User research ‚Üí Wireframes ‚Üí Mockups ‚Üí Prototype ‚Üí User testing
   - Accessibility-first design
   - Mobile-first responsive design

2. **Accessibility Checklist**
   - Keyboard navigation support
   - Screen reader compatibility (ARIA labels)
   - Color contrast ratios (4.5:1 minimum)
   - Focus indicators visible
   - Error messages descriptive
   - Touch targets 44x44px minimum

3. **Design System Guidelines**
   - Use shadcn/ui components as base
   - Extend with custom variants
   - Maintain consistent spacing scale (4px base)
   - Use semantic color tokens
   - Document component variants

**Input/Output Contract**:
```typescript
// Input from orchestrator
interface UIUXTask {
  type: "design" | "audit" | "improve" | "accessibility"
  component?: string  // "VideoPlayer" | "ChatPanel"
  requirements: string[]
  constraints?: string[]  // ["mobile-first", "RTL support"]
}

// Output to orchestrator
interface UIUXResult {
  designFiles?: string[]  // Figma links or descriptions
  accessibilityReport: {
    wcagLevel: "A" | "AA" | "AAA"
    issuesFound: string[]
    issuesFixed: string[]
  }
  recommendations: string[]
  visualExamples?: string[]  // Screenshots or mockups
}
```

---

### 2.5 DevOps Engineer Agent

**Model**: `claude-haiku-4` (cost-effective for infrastructure)

**Domain Expertise**:
- Docker containerization
- CI/CD pipelines (GitHub Actions, GitLab CI)
- Vercel deployment
- Self-hosted deployment
- Environment variable management
- Monitoring and logging (Sentry, LogRocket)
- Performance monitoring (Lighthouse, Web Vitals)
- Database migrations
- Backup strategies

**Specific Skills for LearnWithAvi**:
- Next.js deployment optimization
- ChromaDB service deployment
- Environment variable security
- Vercel configuration (next.config.ts)
- Docker Compose for local development
- Production build optimization (Webpack)
- API key rotation strategy
- Cost monitoring (Anthropic, OpenAI usage)

**Methodologies**:
1. **Deployment Pipeline**
   ```
   Git Push ‚Üí Build ‚Üí Test ‚Üí Deploy (Preview) ‚Üí User Approval ‚Üí Deploy (Production)
   ```
   - Automated testing before deploy
   - Preview deployments for PRs
   - Blue-green deployment for zero downtime

2. **Monitoring Setup**
   - Error tracking (Sentry)
   - Performance monitoring (Web Vitals)
   - API usage tracking (Anthropic, OpenAI)
   - Uptime monitoring
   - Alert configuration (Slack, email)

3. **Security Best Practices**
   - Environment variables in secure vaults
   - API key rotation schedule
   - Dependency vulnerability scanning
   - Docker image scanning
   - SSL/TLS certificates

**Input/Output Contract**:
```typescript
// Input from orchestrator
interface DevOpsTask {
  type: "deploy" | "monitor" | "optimize" | "security"
  environment?: "development" | "staging" | "production"
  requirements: string[]
  constraints?: string[]  // ["zero-downtime", "rollback-ready"]
}

// Output to orchestrator
interface DevOpsResult {
  deploymentURL?: string
  filesModified: string[]  // docker-compose.yml, .github/workflows
  metrics: {
    buildTime: string      // "45 seconds"
    deployTime: string     // "2 minutes"
    bundleSize: string     // "240KB gzipped"
  }
  healthChecks: {
    api: boolean
    database: boolean
    vectorDB: boolean
  }
}
```

---

### 2.6 QA Engineer Agent

**Model**: `claude-haiku-4` (test execution) / `claude-sonnet-4-5` (test design)

**Domain Expertise**:
- Unit testing (Vitest)
- Integration testing (Vitest + Testing Library)
- E2E testing (Playwright)
- Visual regression testing
- Performance testing (Lighthouse)
- Load testing (k6)
- Test coverage analysis
- Bug reporting and reproduction

**Specific Skills for LearnWithAvi**:
- Testing React components with streaming data
- Testing video player interactions
- Testing chat interface with SSE
- Testing voice input/output
- Testing RTL layouts
- Testing API endpoints with mocking
- Testing RAG pipeline accuracy
- Accessibility testing (axe-core)

**Methodologies**:
1. **Testing Pyramid**
   ```
           /\
          /E2E\        10% - Full user flows
         /‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\
        /INTEGR\       30% - Component + API
       /‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\
      /   UNIT   \     60% - Functions, utilities
     /‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\
   ```

2. **Test Coverage Goals**
   - Unit tests: 80% coverage minimum
   - Integration tests: Critical user flows
   - E2E tests: Happy paths + error scenarios
   - Accessibility: 100% WCAG AA compliance

3. **Test Automation Strategy**
   - Run unit tests on every commit
   - Run integration tests on PR creation
   - Run E2E tests before production deploy
   - Weekly full regression suite

**Input/Output Contract**:
```typescript
// Input from orchestrator
interface QATask {
  type: "unit" | "integration" | "e2e" | "accessibility" | "performance"
  scope: string[]  // File paths or component names
  requirements: string[]
  coverageTarget?: number  // 80
}

// Output to orchestrator
interface QAResult {
  testsCreated: string[]
  testsModified: string[]
  testResults: {
    passed: number
    failed: number
    skipped: number
  }
  coverage: {
    statements: number
    branches: number
    functions: number
    lines: number
  }
  issues: {
    critical: string[]
    major: string[]
    minor: string[]
  }
}
```

---

### 2.7 Product Manager Agent

**Model**: `claude-sonnet-4-5`

**Domain Expertise**:
- Product requirements documentation (PRDs)
- User story writing (As a... I want... So that...)
- Acceptance criteria definition
- Roadmap planning and prioritization
- Feature prioritization (RICE, MoSCoW)
- Stakeholder communication
- Competitive analysis
- User feedback analysis
- Success metrics definition (KPIs)

**Specific Skills for LearnWithAvi**:
- EdTech product patterns
- Learning platform UX
- Video learning engagement metrics
- AI tutor interaction design
- Learner journey mapping
- Course content structure
- Gamification strategies (progress, achievements)
- Monetization strategy (freemium, premium)

**Methodologies**:
1. **User Story Format**
   ```
   As a [learner persona]
   I want [feature/capability]
   So that [benefit/outcome]

   Acceptance Criteria:
   - [ ] Criterion 1 (testable)
   - [ ] Criterion 2 (testable)
   - [ ] Criterion 3 (testable)
   ```

2. **Prioritization Framework (RICE)**
   - **Reach**: How many users affected? (per quarter)
   - **Impact**: How much value per user? (0.25, 0.5, 1, 2, 3)
   - **Confidence**: How certain are estimates? (50%, 80%, 100%)
   - **Effort**: How much work? (person-months)
   - **Score**: (Reach √ó Impact √ó Confidence) / Effort

3. **Success Metrics**
   - **Engagement**: Daily active users, session time, videos watched
   - **Learning**: Quiz scores, course completion, time to completion
   - **AI Interaction**: Questions asked, voice usage, satisfaction ratings
   - **Business**: User retention, upgrade rate, NPS score

**Input/Output Contract**:
```typescript
// Input from orchestrator
interface ProductTask {
  type: "prd" | "user_story" | "prioritization" | "analysis"
  feature?: string  // "Voice AI Tutor" | "Quiz System"
  requirements: string[]
  context?: string  // User feedback, competitive analysis
}

// Output to orchestrator
interface ProductResult {
  documentsCreated: string[]  // PRD, user stories
  userStories: {
    title: string
    description: string
    acceptanceCriteria: string[]
    priority: "P0" | "P1" | "P2" | "P3"
    riceScore?: number
  }[]
  recommendations: string[]
  successMetrics: {
    metric: string
    target: string
    measurement: string
  }[]
}
```

---

## 3. Agent Communication Protocol

### Message Format

All agents communicate using a standardized message format:

```typescript
interface AgentMessage {
  from: AgentID  // "orchestrator" | "frontend" | "backend" | ...
  to: AgentID | AgentID[]  // Single agent or multiple agents
  type: "task" | "status" | "result" | "question" | "error"
  priority: "critical" | "high" | "medium" | "low"
  timestamp: ISO8601String
  content: TaskContent | StatusUpdate | Result | Question | Error
  context?: {
    userRequest: string
    relatedTasks: TaskID[]
    dependencies: AgentID[]
  }
}

// Task assignment
interface TaskContent {
  taskId: string
  description: string
  requirements: string[]
  acceptanceCriteria: string[]
  constraints?: string[]
  deadline?: ISO8601String
  references?: {
    files: string[]
    documentation: string[]
    externalLinks: string[]
  }
}

// Status update
interface StatusUpdate {
  taskId: string
  status: "queued" | "in_progress" | "blocked" | "completed" | "failed"
  progress: number  // 0-100
  message: string
  blockers?: {
    description: string
    blockedBy: AgentID[]
    estimatedResolution: ISO8601String
  }[]
}

// Result delivery
interface Result {
  taskId: string
  success: boolean
  output: Record<string, any>  // Agent-specific result format
  artifacts?: {
    files: string[]
    documentation: string[]
    tests: string[]
  }
  nextSteps?: string[]
}

// Question for clarification
interface Question {
  taskId: string
  question: string
  options?: string[]
  requiredBy: ISO8601String
  criticalPath: boolean
}

// Error report
interface Error {
  taskId: string
  errorType: "blocker" | "warning" | "info"
  message: string
  stackTrace?: string
  suggestedResolution?: string
  escalate: boolean
}
```

### Communication Patterns

#### 1. Single Agent Task
```
User ‚Üí Orchestrator ‚Üí Frontend Engineer ‚Üí Orchestrator ‚Üí User
```

#### 2. Sequential Task Chain
```
User ‚Üí Orchestrator ‚Üí UI/UX Designer ‚Üí Frontend Engineer ‚Üí QA Engineer ‚Üí Orchestrator ‚Üí User
```

#### 3. Parallel Task Execution
```
                  ‚îå‚Üí Frontend Engineer ‚îÄ‚îê
User ‚Üí Orchestrator ‚îº‚Üí Backend Engineer ‚îÄ‚îÄ‚î§‚Üí Orchestrator ‚Üí User
                  ‚îî‚Üí RAG Specialist ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 4. Parallel-then-Coordinate
```
                  ‚îå‚Üí Frontend Engineer ‚îÄ‚îê
User ‚Üí Orchestrator ‚îº‚Üí Backend Engineer ‚îÄ‚îÄ‚î§‚Üí DevOps Engineer ‚Üí Orchestrator ‚Üí User
                  ‚îî‚Üí QA Engineer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 4. Task Execution Examples

### Example 1: Add New Video to Platform

**User Request**: "Add the new YouTube video 'XYZ123' to the platform with automatic chapter generation"

**Orchestrator Analysis**:
- Domains: Backend (YouTube API), RAG (transcript processing), Frontend (display)
- Pattern: Sequential (Backend ‚Üí RAG ‚Üí Frontend)

**Execution Flow**:
```
1. Orchestrator ‚Üí Backend Engineer
   Task: "Fetch YouTube video metadata and transcript"
   - Use YouTube API to get title, duration, description
   - Use Whisper API to generate transcript if not available
   - Store in video-config.ts

2. Backend Engineer ‚Üí RAG Specialist (sequential dependency)
   Handoff: "Transcript ready for processing"
   Task: "Generate semantic chunks and auto-chapters"
   - Chunk transcript with timestamp alignment
   - Generate embeddings for semantic search
   - Auto-generate 3-10 chapters based on topic shifts
   - Store in data/transcripts/ directory

3. RAG Specialist ‚Üí Frontend Engineer (sequential dependency)
   Handoff: "Video data and chapters ready"
   Task: "Add video to UI with chapter timeline"
   - Update courses.ts with new video entry
   - Verify VideoPlayer displays chapters correctly
   - Test chapter navigation and timestamp sync

4. Frontend Engineer ‚Üí QA Engineer (sequential dependency)
   Handoff: "Video integration complete"
   Task: "Test new video end-to-end"
   - Verify video loads and plays
   - Test chapter navigation
   - Test transcript display sync
   - Test chat with video context

5. QA Engineer ‚Üí Orchestrator ‚Üí User
   Result: "New video XYZ123 successfully added and tested"
```

### Example 2: Implement Voice AI Tutor

**User Request**: "Implement the voice-to-voice AI tutor feature"

**Orchestrator Analysis**:
- Domains: Product (requirements), UI/UX (interface), Backend (APIs), Frontend (voice UI)
- Pattern: Sequential for planning, then Parallel, then Sequential for integration

**Execution Flow**:
```
1. Orchestrator ‚Üí Product Manager
   Task: "Define voice AI tutor requirements and UX flow"
   Output: PRD with user stories, success metrics

2. Product Manager ‚Üí UI/UX Designer (sequential dependency)
   Handoff: "Voice tutor requirements defined"
   Task: "Design voice interaction UI"
   - Recording indicator
   - Voice waveform visualization
   - Listening/Thinking/Speaking states
   - Error states (mic permission, API failures)
   Output: Design mockups and accessibility guidelines

3. Orchestrator ‚Üí [Backend Engineer, Frontend Engineer] (parallel execution)

   Backend Engineer Task:
   - Integrate OpenAI Whisper for STT
   - Integrate ElevenLabs for TTS
   - Create WebSocket server for low-latency voice
   - Implement audio streaming endpoints

   Frontend Engineer Task:
   - Implement voice recording UI with waveform
   - Create useVoiceInput hook (MediaRecorder API)
   - Create useVoiceOutput hook (Audio API)
   - Add voice button to ChatPanel
   - Handle loading/error states

4. [Backend Engineer, Frontend Engineer] ‚Üí DevOps Engineer (coordination)
   Handoff: "Voice APIs and UI ready for integration"
   Task: "Deploy voice endpoints and configure environment"
   - Add ELEVENLABS_API_KEY to environment
   - Configure WebSocket server
   - Set up SSL for secure audio streaming

5. DevOps Engineer ‚Üí QA Engineer (sequential dependency)
   Task: "Test voice AI tutor end-to-end"
   - Test voice recording in different browsers
   - Test TTS playback quality
   - Test latency (target: <2s round-trip)
   - Test error handling (network failures, mic permission)
   - Accessibility testing (keyboard shortcuts, screen reader)

6. QA Engineer ‚Üí Orchestrator ‚Üí User
   Result: "Voice AI tutor feature complete and tested"
```

### Example 3: Optimize RAG Pipeline Performance

**User Request**: "The chat responses are slow and sometimes irrelevant. Optimize the RAG pipeline."

**Orchestrator Analysis**:
- Domains: RAG Specialist (primary), Backend (caching), QA (evaluation)
- Pattern: Single agent with support

**Execution Flow**:
```
1. Orchestrator ‚Üí RAG Specialist
   Task: "Diagnose and optimize RAG pipeline performance"

2. RAG Specialist performs analysis:
   - Measure current metrics (latency, precision, recall)
   - Identify bottlenecks (embedding generation, vector search, re-ranking)
   - Implement optimizations:
     * Enable hybrid search (semantic + keyword)
     * Optimize chunk size (reduce from 1000 to 800 tokens)
     * Add semantic re-ranking with cross-encoder
     * Improve prompt caching strategy

3. RAG Specialist ‚Üí Backend Engineer (request support)
   Question: "Need LRU cache for embeddings with 1-hour TTL"
   Backend Engineer implements embeddings-cache.ts

4. Backend Engineer ‚Üí RAG Specialist (handoff)
   Handoff: "Embedding cache ready"
   RAG Specialist integrates cache into rag.ts

5. RAG Specialist ‚Üí QA Engineer (request evaluation)
   Task: "Evaluate RAG improvements"
   QA Engineer runs evaluation suite:
   - Before: 2.5s avg latency, 60% precision, 45% recall
   - After: 1.1s avg latency, 78% precision, 68% recall
   - Cost: -30% (embedding cache) + -75% (prompt cache) = -82% total

6. QA Engineer ‚Üí Orchestrator ‚Üí User
   Result: "RAG pipeline optimized: 56% faster, 30% more accurate, 82% cheaper"
```

### Example 4: Fix Critical Bug

**User Request**: "The video player crashes when switching between videos"

**Orchestrator Analysis**:
- Domains: Frontend (video player), QA (reproduction)
- Pattern: Single agent (Frontend Engineer)

**Execution Flow**:
```
1. Orchestrator ‚Üí QA Engineer (quick task)
   Task: "Reproduce the video switching crash"
   QA Engineer reproduces:
   - Crash occurs when switching videos before previous video unloads
   - Error: "Cannot read property 'destroy' of null"
   - Browser console shows YouTube player cleanup race condition

2. QA Engineer ‚Üí Frontend Engineer (handoff)
   Handoff: "Bug reproduced, race condition in VideoPlayer.tsx:215"
   Task: "Fix video player cleanup race condition"

3. Frontend Engineer analyzes and fixes:
   - Root cause: useEffect cleanup not waiting for player.destroy()
   - Solution: Add ref to track mounted state, await destroy()
   - Add defensive null checks before cleanup
   - Verify fix with multiple rapid video switches

4. Frontend Engineer ‚Üí QA Engineer (request testing)
   Task: "Verify video switching bug is fixed"
   QA Engineer tests:
   - ‚úÖ Rapid video switching (10 switches in 5 seconds)
   - ‚úÖ Switch during video loading
   - ‚úÖ Switch during video playback
   - ‚úÖ No console errors

5. QA Engineer ‚Üí Orchestrator ‚Üí User
   Result: "Video switching crash fixed and verified"
```

---

## 5. Agent Configuration File

The orchestrator uses [agents/config.json](agents/config.json) to configure all sub-agents. This file should be located at the project root:

```json
{
  "orchestrator": {
    "name": "orchestrator",
    "display_name": "Project Manager AI",
    "model": "claude-sonnet-4-5-20251101",
    "role": "Orchestrator and task coordinator",
    "description": "Analyzes user requests, decomposes complex tasks, delegates to specialized sub-agents, and coordinates their work",
    "capabilities": [
      "task_analysis",
      "agent_selection",
      "dependency_management",
      "progress_tracking",
      "conflict_resolution",
      "quality_assurance"
    ]
  },
  "agents": [
    {
      "name": "frontend-engineer",
      "display_name": "Frontend Engineer",
      "model": "claude-sonnet-4-5-20251101",
      "fallback_model": "claude-haiku-4",
      "role": "React and Next.js specialist",
      "description": "Develops UI components, manages client-side state, optimizes frontend performance",
      "expertise": [
        "React 19",
        "Next.js 16 App Router",
        "TypeScript 5",
        "Tailwind CSS 4",
        "shadcn/ui",
        "Client-side state management",
        "Performance optimization"
      ],
      "skills": [
        "/skills/frontend-engineer/SKILL.md"
      ],
      "tools": [
        "Read",
        "Edit",
        "Write",
        "Glob",
        "Grep",
        "Bash"
      ],
      "context_files": [
        "src/components/**/*.tsx",
        "src/app/**/page.tsx",
        "src/hooks/**/*.ts",
        "src/types/index.ts"
      ]
    },
    {
      "name": "backend-engineer",
      "display_name": "Backend Engineer",
      "model": "claude-sonnet-4-5-20251101",
      "role": "API and database specialist",
      "description": "Develops server-side APIs, integrates external services, manages database schema and migrations",
      "expertise": [
        "Node.js + TypeScript",
        "Next.js API Routes",
        "RESTful API design",
        "Server-Sent Events (SSE)",
        "PostgreSQL + Prisma",
        "Authentication (Clerk)",
        "Rate limiting",
        "Error sanitization"
      ],
      "skills": [
        "/skills/backend-engineer/SKILL.md"
      ],
      "tools": [
        "Read",
        "Edit",
        "Write",
        "Glob",
        "Grep",
        "Bash"
      ],
      "context_files": [
        "src/app/api/**/*.ts",
        "src/lib/**/*.ts",
        "prisma/schema.prisma",
        ".env.example"
      ]
    },
    {
      "name": "rag-specialist",
      "display_name": "RAG Pipeline Specialist",
      "model": "claude-sonnet-4-5-20251101",
      "role": "Vector search and retrieval specialist",
      "description": "Optimizes RAG pipeline, improves retrieval accuracy, manages embeddings and vector databases",
      "expertise": [
        "Vector embeddings (OpenAI, Anthropic)",
        "Vector databases (ChromaDB)",
        "Semantic search",
        "Hybrid search (semantic + keyword)",
        "Retrieval evaluation (precision, recall, MRR)",
        "Chunking strategies",
        "Prompt engineering for RAG",
        "Multilingual embeddings (Hebrew)"
      ],
      "skills": [
        "/skills/rag-pipeline-optimizer/SKILL.md"
      ],
      "tools": [
        "Read",
        "Edit",
        "Write",
        "Glob",
        "Grep",
        "Bash"
      ],
      "context_files": [
        "src/lib/rag.ts",
        "src/lib/embeddings.ts",
        "src/lib/embeddings-cache.ts",
        "src/data/transcripts/**/*.json"
      ]
    },
    {
      "name": "ui-ux-designer",
      "display_name": "UI/UX Designer",
      "model": "claude-sonnet-4-5-20251101",
      "role": "Interface design and accessibility specialist",
      "description": "Designs user interfaces, ensures accessibility compliance (WCAG 2.1 AA), optimizes user experience",
      "expertise": [
        "User interface design",
        "Accessibility (WCAG 2.1 AA)",
        "Responsive design (mobile-first)",
        "Design systems (shadcn/ui, Radix UI)",
        "Color theory and contrast",
        "Typography and readability",
        "User flow design",
        "Interaction patterns"
      ],
      "skills": [
        "/skills/ui-ux-designer/SKILL.md"
      ],
      "tools": [
        "Read",
        "Glob",
        "Grep"
      ],
      "context_files": [
        "src/components/**/*.tsx",
        "src/app/**/layout.tsx",
        "tailwind.config.mjs",
        "src/components/ui/**/*.tsx"
      ]
    },
    {
      "name": "devops-engineer",
      "display_name": "DevOps Engineer",
      "model": "claude-haiku-4",
      "role": "Deployment and infrastructure specialist",
      "description": "Manages deployments, configures CI/CD, monitors production, optimizes infrastructure",
      "expertise": [
        "Docker containerization",
        "CI/CD pipelines (GitHub Actions)",
        "Vercel deployment",
        "Environment management",
        "Monitoring and logging",
        "Performance monitoring (Lighthouse)",
        "Database migrations",
        "Security best practices"
      ],
      "skills": [
        "/skills/devops-engineer/SKILL.md"
      ],
      "tools": [
        "Read",
        "Edit",
        "Write",
        "Bash"
      ],
      "context_files": [
        "next.config.ts",
        "docker-compose.yml",
        "Dockerfile",
        ".github/workflows/**/*.yml",
        ".env.example"
      ]
    },
    {
      "name": "qa-engineer",
      "display_name": "QA Engineer",
      "model": "claude-haiku-4",
      "upgrade_model": "claude-sonnet-4-5-20251101",
      "role": "Testing and quality assurance specialist",
      "description": "Writes and runs tests (unit, integration, E2E), evaluates quality metrics, reports bugs",
      "expertise": [
        "Unit testing (Vitest)",
        "Integration testing (Testing Library)",
        "E2E testing (Playwright)",
        "Visual regression testing",
        "Performance testing (Lighthouse)",
        "Test coverage analysis",
        "Bug reporting",
        "Accessibility testing (axe-core)"
      ],
      "skills": [
        "/skills/qa-engineer/SKILL.md"
      ],
      "tools": [
        "Read",
        "Edit",
        "Write",
        "Bash",
        "Glob",
        "Grep"
      ],
      "context_files": [
        "src/**/*.test.ts",
        "src/**/*.test.tsx",
        "e2e/**/*.spec.ts",
        "vitest.config.ts",
        "playwright.config.ts"
      ]
    },
    {
      "name": "product-manager",
      "display_name": "Product Manager",
      "model": "claude-sonnet-4-5-20251101",
      "role": "Product strategy and requirements specialist",
      "description": "Writes product requirements (PRDs), defines user stories, prioritizes features, analyzes user feedback",
      "expertise": [
        "Product requirements (PRDs)",
        "User story writing",
        "Acceptance criteria",
        "Roadmap planning",
        "Feature prioritization (RICE, MoSCoW)",
        "Stakeholder communication",
        "Success metrics (KPIs)",
        "EdTech product patterns"
      ],
      "skills": [
        "/skills/product-manager/SKILL.md"
      ],
      "tools": [
        "Read",
        "Write",
        "Glob",
        "Grep"
      ],
      "context_files": [
        "LearnWithAvi-PRD.md",
        "docs/**/*.md",
        "README.md"
      ]
    }
  ],
  "execution_patterns": {
    "single": {
      "description": "One agent handles the entire task",
      "example": "Fix a CSS bug in VideoPlayer component ‚Üí Frontend Engineer"
    },
    "sequential": {
      "description": "Agents work in order, each depending on previous completion",
      "example": "Add new feature ‚Üí Product Manager ‚Üí UI/UX Designer ‚Üí Frontend Engineer ‚Üí QA Engineer"
    },
    "parallel": {
      "description": "Multiple agents work simultaneously on independent tasks",
      "example": "Optimize performance ‚Üí [Frontend Engineer, Backend Engineer, RAG Specialist] work in parallel"
    },
    "parallel_then_coordinate": {
      "description": "Agents work in parallel, then coordinate to integrate results",
      "example": "Launch new feature ‚Üí [Frontend Engineer, Backend Engineer] parallel ‚Üí DevOps Engineer coordinates deployment"
    }
  },
  "coordination_rules": {
    "conflict_resolution": "Orchestrator makes final decisions on conflicts",
    "quality_gates": [
      "All code changes must pass QA Engineer tests",
      "All UI changes must pass UI/UX Designer accessibility audit",
      "All API changes must pass Backend Engineer security review"
    ],
    "communication": "All agents must report status every 5 minutes during active work",
    "escalation": "Agents escalate blockers to orchestrator immediately"
  }
}
```

---

## 6. Orchestrator Decision Algorithm

The orchestrator uses this decision tree to select agents and execution patterns:

```python
def orchestrate(user_request: str) -> ExecutionPlan:
    """
    Orchestrator's main decision algorithm
    """

    # Step 1: Parse and analyze request
    analysis = analyze_request(user_request)
    domains = analysis.required_domains  # ["frontend", "backend", ...]
    complexity = analysis.complexity      # "trivial" | "simple" | "moderate" | "complex"
    urgency = analysis.urgency           # "critical" | "high" | "medium" | "low"

    # Step 2: Handle special cases
    if analysis.type == "question":
        return answer_directly()  # Orchestrator answers without delegation

    if analysis.type == "clarification_needed":
        return ask_user_for_clarification()

    # Step 3: Select agents based on domains
    agents = select_agents(domains)

    # Step 4: Determine execution pattern
    if len(agents) == 1:
        pattern = "single"
    elif has_strict_dependencies(analysis):
        pattern = "sequential"
        agents = topological_sort(agents, analysis.dependencies)
    elif has_no_dependencies(analysis):
        pattern = "parallel"
    else:
        pattern = "parallel_then_coordinate"
        phases = split_into_phases(agents, analysis.dependencies)

    # Step 5: Create execution plan
    plan = ExecutionPlan(
        pattern=pattern,
        agents=agents,
        tasks=decompose_into_tasks(user_request, agents),
        dependencies=analysis.dependencies,
        quality_gates=determine_quality_gates(agents),
        estimated_duration=estimate_duration(complexity, len(agents)),
        priority=urgency
    )

    # Step 6: Execute plan
    return execute_plan(plan)

def select_agents(domains: list[str]) -> list[Agent]:
    """
    Select agents based on required domains
    """
    agent_mapping = {
        "ui": "ui-ux-designer",
        "frontend": "frontend-engineer",
        "backend": "backend-engineer",
        "api": "backend-engineer",
        "database": "backend-engineer",
        "rag": "rag-specialist",
        "vector": "rag-specialist",
        "embeddings": "rag-specialist",
        "deployment": "devops-engineer",
        "infrastructure": "devops-engineer",
        "testing": "qa-engineer",
        "quality": "qa-engineer",
        "product": "product-manager",
        "requirements": "product-manager"
    }

    agents = []
    for domain in domains:
        agent_name = agent_mapping.get(domain)
        if agent_name and agent_name not in agents:
            agents.append(get_agent(agent_name))

    return agents

def has_strict_dependencies(analysis: Analysis) -> bool:
    """
    Check if tasks have strict sequential dependencies
    """
    # Examples of strict dependencies:
    # - Design must complete before implementation
    # - Backend API must exist before frontend integration
    # - Tests must run after code changes
    return len(analysis.dependencies) > 0 and is_dag(analysis.dependencies)

def has_no_dependencies(analysis: Analysis) -> bool:
    """
    Check if tasks are completely independent
    """
    # Examples of independent tasks:
    # - Optimize frontend performance + Optimize backend performance
    # - Fix bug in VideoPlayer + Fix bug in ChatPanel
    # - Add tests for component A + Add tests for component B
    return len(analysis.dependencies) == 0
```

---

## 7. Usage Examples for User

### How to Invoke the Orchestrator

The orchestrator is invoked automatically by Claude Code when you provide a task. You can explicitly request multi-agent coordination:

#### Example 1: Automatic Agent Selection
```
You: "Add a progress bar to the video player"

Orchestrator:
  ‚îú‚îÄ Analyzing request...
  ‚îú‚îÄ Domains: UI design, Frontend implementation, Testing
  ‚îú‚îÄ Pattern: Sequential
  ‚îú‚îÄ Agents: UI/UX Designer ‚Üí Frontend Engineer ‚Üí QA Engineer
  ‚îî‚îÄ Starting execution...

UI/UX Designer:
  ‚úì Designed progress bar component (blue gradient, smooth animation)
  ‚úì Accessibility: ARIA labels, keyboard navigation (left/right arrows)
  ‚Üí Handing off to Frontend Engineer...

Frontend Engineer:
  ‚úì Implemented ProgressBar component in VideoPlayer.tsx
  ‚úì Added state management for current time / duration
  ‚úì Integrated with video playback events
  ‚Üí Handing off to QA Engineer...

QA Engineer:
  ‚úì Unit tests for ProgressBar component (100% coverage)
  ‚úì Integration test with VideoPlayer
  ‚úì Accessibility test (WCAG AA compliant)
  ‚Üí Task complete!

Orchestrator ‚Üí You:
  ‚úì Progress bar added successfully
  üì¶ Files modified: VideoPlayer.tsx, ProgressBar.tsx, VideoPlayer.test.tsx
  üìä Tests: 12 passed, 0 failed
  ‚ôø Accessibility: WCAG AA compliant
```

#### Example 2: Explicit Multi-Agent Request
```
You: "I need a comprehensive performance audit and optimization across the entire platform"

Orchestrator:
  ‚îú‚îÄ Analyzing request...
  ‚îú‚îÄ Domains: Frontend performance, Backend performance, RAG performance
  ‚îú‚îÄ Pattern: Parallel execution
  ‚îú‚îÄ Agents: Frontend Engineer + Backend Engineer + RAG Specialist
  ‚îî‚îÄ Starting parallel execution...

[PARALLEL EXECUTION - 3 agents working simultaneously]

Frontend Engineer:
  üîç Auditing frontend performance...
  - Bundle size: 420KB (target: <300KB)
  - FCP: 1.8s (target: <1.5s)
  - LCP: 3.2s (target: <2.5s)
  ‚ö° Optimizations:
  - Lazy load VideoPlayer component (-80KB)
  - Tree-shake unused Radix UI components (-30KB)
  - Code split chat and voice modules (-50KB)
  ‚úì New bundle size: 260KB (-38%)
  ‚úì New FCP: 1.2s (-33%)
  ‚úì New LCP: 1.9s (-41%)

Backend Engineer:
  üîç Auditing backend performance...
  - Chat API latency: 2.1s (target: <1.5s)
  - TTS API latency: 3.5s (target: <2.0s)
  ‚ö° Optimizations:
  - Enable API response caching (Redis)
  - Reduce Claude max_tokens for simple queries
  - Stream TTS audio chunks (no wait for full generation)
  ‚úì New chat latency: 1.1s (-48%)
  ‚úì New TTS latency: 1.6s (-54%)

RAG Specialist:
  üîç Auditing RAG pipeline performance...
  - Embedding generation: 800ms (target: <500ms)
  - Vector search: 300ms (target: <200ms)
  - Relevance: 72% precision (target: >80%)
  ‚ö° Optimizations:
  - Batch embedding generation (5x speedup)
  - Implement hybrid search (semantic + keyword)
  - Add semantic re-ranking layer
  ‚úì New embedding time: 180ms (-78%)
  ‚úì New search time: 150ms (-50%)
  ‚úì New precision: 84% (+17%)

Orchestrator ‚Üí You:
  ‚úì Platform-wide performance optimization complete!

  üìä Results Summary:
  Frontend: -38% bundle size, -33% FCP, -41% LCP
  Backend:  -48% chat latency, -54% TTS latency
  RAG:      -78% embedding time, -50% search time, +17% precision

  üí∞ Cost Impact: -45% monthly API costs ($213 ‚Üí $117)
  üöÄ Overall: Platform is 2x faster across all metrics
```

#### Example 3: Requesting a Specific Agent
```
You: "Frontend Engineer, please add a dark mode toggle to the navigation bar"

Frontend Engineer (direct invocation):
  ‚úì Added DarkModeToggle component
  ‚úì Integrated with existing dark mode context
  ‚úì Positioned in navigation bar (top right)
  ‚úì Icon: Sun (light mode) / Moon (dark mode)
  ‚úì Keyboard shortcut: Cmd+Shift+D
  ‚Üí Task complete!
```

#### Example 4: Complex Multi-Phase Task
```
You: "I want to add a quiz system where learners can test their knowledge after each video"

Orchestrator:
  ‚îú‚îÄ Analyzing request...
  ‚îú‚îÄ Domains: Product planning, UI design, Backend, Frontend, Testing
  ‚îú‚îÄ Pattern: Sequential phases with parallel execution
  ‚îú‚îÄ Estimated complexity: High (multi-day task)
  ‚îî‚îÄ Breaking down into phases...

PHASE 1: Planning and Design
  Product Manager:
    ‚úì Wrote PRD for quiz system (docs/QUIZ_SYSTEM_PRD.md)
    ‚úì Defined user stories:
      - As a learner, I want to take quizzes after videos to test my understanding
      - As a learner, I want to see my quiz results and track progress
      - As a learner, I want hints for difficult questions
    ‚úì Success metrics: >60% quiz completion rate, >70% average score

  UI/UX Designer:
    ‚úì Designed quiz interface (modal overlay)
    ‚úì Question types: Multiple choice, True/False, Code snippet
    ‚úì Progress indicator (Question 3 of 10)
    ‚úì Immediate feedback (correct/incorrect with explanations)
    ‚úì Results screen (score, time taken, review incorrect answers)

PHASE 2: Implementation (Parallel)
  [Backend Engineer + Frontend Engineer work in parallel]

  Backend Engineer:
    ‚úì Created Prisma schema for quizzes (Question, Answer, UserQuizResult)
    ‚úì API endpoint: POST /api/quiz/generate (auto-generate from video)
    ‚úì API endpoint: POST /api/quiz/submit (validate answers)
    ‚úì API endpoint: GET /api/quiz/results (get user stats)
    ‚úì Integration with Claude API for quiz generation

  Frontend Engineer:
    ‚úì Created QuizModal component
    ‚úì Created QuestionCard component (reusable for all question types)
    ‚úì Created ResultsScreen component
    ‚úì Added "Take Quiz" button to video player
    ‚úì State management with useQuiz hook
    ‚úì Keyboard shortcuts (1-4 for answers, Enter to submit)

PHASE 3: Integration and Testing
  DevOps Engineer:
    ‚úì Added database migrations for quiz tables
    ‚úì Deployed to staging environment

  QA Engineer:
    ‚úì Unit tests for quiz components (95% coverage)
    ‚úì Integration tests for quiz API endpoints
    ‚úì E2E test: Complete quiz flow (start ‚Üí answer ‚Üí submit ‚Üí results)
    ‚úì Accessibility test: Keyboard navigation, screen reader
    ‚úì Load test: 100 concurrent quiz submissions (99% success rate)

Orchestrator ‚Üí You:
  ‚úì Quiz system fully implemented and tested!

  üì¶ Files created:
  - Backend: src/app/api/quiz/**.ts (3 endpoints)
  - Frontend: src/components/quiz/**.tsx (5 components)
  - Database: prisma/migrations/20260116_add_quiz_system.sql
  - Tests: src/**/*.test.ts (18 test files, 127 tests)
  - Docs: docs/QUIZ_SYSTEM_PRD.md

  üìä Quality Metrics:
  - Test coverage: 95%
  - Accessibility: WCAG AA compliant
  - Performance: <100ms quiz submission latency

  üöÄ Ready to deploy to production!

  Next steps:
  1. Review quiz generation quality with sample videos
  2. Consider adding more question types (fill-in-blank, matching)
  3. Implement spaced repetition algorithm for quiz scheduling
```

---

## 8. Best Practices

### For Orchestrator

1. **Always analyze before delegating**
   - Understand the full scope of the request
   - Identify all required domains
   - Check for hidden dependencies

2. **Choose the right execution pattern**
   - Single agent for simple, isolated tasks
   - Sequential for strict dependencies
   - Parallel for independent tasks
   - Parallel-then-coordinate for complex integration

3. **Monitor progress continuously**
   - Track agent status every 5 minutes
   - Unblock agents immediately
   - Escalate critical issues to user

4. **Ensure quality gates**
   - All code changes must be tested
   - All UI changes must be accessible
   - All API changes must be secure

### For Sub-Agents

1. **Communicate status proactively**
   - Report progress regularly
   - Escalate blockers immediately
   - Ask questions when unclear

2. **Follow domain expertise**
   - Stay within your area of expertise
   - Request handoff when crossing domains
   - Don't make assumptions about other domains

3. **Document your work**
   - Comment complex code
   - Update documentation
   - Provide clear handoff notes

4. **Test your changes**
   - Self-test before handing off to QA
   - Verify acceptance criteria
   - Check for edge cases

---

## 9. Monitoring and Metrics

### Task Execution Metrics

Track these metrics for each task:

```typescript
interface TaskMetrics {
  taskId: string
  userRequest: string
  orchestratorAnalysisTime: number  // ms
  agentSelectionTime: number        // ms
  totalExecutionTime: number        // ms
  agentsInvolved: AgentID[]
  executionPattern: "single" | "sequential" | "parallel" | "parallel_then_coordinate"
  success: boolean
  qualityScore: number              // 0-100
  userSatisfaction?: number         // 1-5 stars
}
```

### Agent Performance Metrics

Track these metrics for each agent:

```typescript
interface AgentMetrics {
  agentId: AgentID
  tasksCompleted: number
  tasksBlockedByAgent: number
  averageTaskTime: number           // ms
  successRate: number               // 0-100%
  qualityScore: number              // 0-100
  bottleneck: boolean               // Is this agent slowing down others?
}
```

### System Health Dashboard

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               LEARNWITHAVI AGENT METRICS                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Orchestrator Performance:                                   ‚îÇ
‚îÇ   Tasks completed today: 47                                 ‚îÇ
‚îÇ   Average delegation time: 1.2s                             ‚îÇ
‚îÇ   Success rate: 94%                                         ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ Agent Utilization:                                          ‚îÇ
‚îÇ   Frontend Engineer:    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 85%         ‚îÇ
‚îÇ   Backend Engineer:     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 68%         ‚îÇ
‚îÇ   RAG Specialist:       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 35%         ‚îÇ
‚îÇ   UI/UX Designer:       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 28%         ‚îÇ
‚îÇ   DevOps Engineer:      ‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 12%         ‚îÇ
‚îÇ   QA Engineer:          ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 76%         ‚îÇ
‚îÇ   Product Manager:      ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 18%         ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ Bottleneck Alert:                                           ‚îÇ
‚îÇ   ‚ö†Ô∏è  Frontend Engineer is at 85% capacity                 ‚îÇ
‚îÇ   üí° Consider upgrading to claude-opus-4-5 for complex UI  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ Quality Metrics:                                            ‚îÇ
‚îÇ   Average test coverage: 87%                                ‚îÇ
‚îÇ   Accessibility compliance: 100% (WCAG AA)                  ‚îÇ
‚îÇ   Security issues: 0 critical, 2 minor                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 10. Next Steps

### Immediate Actions

1. **Create agents/config.json** (if not exists)
   - Copy the configuration from Section 5 above
   - Customize agent models based on budget
   - Adjust context_files based on project structure

2. **Create skill files** for each agent:
   - `/skills/frontend-engineer/SKILL.md`
   - `/skills/backend-engineer/SKILL.md`
   - `/skills/rag-specialist/SKILL.md` (already exists as rag-pipeline-optimizer)
   - `/skills/ui-ux-designer/SKILL.md` (already exists)
   - `/skills/devops-engineer/SKILL.md`
   - `/skills/qa-engineer/SKILL.md`
   - `/skills/product-manager/SKILL.md` (already exists)

3. **Test orchestrator** with a simple task:
   ```
   You: "Add a 'Report Bug' button to the footer"

   Expected: Orchestrator ‚Üí UI/UX Designer ‚Üí Frontend Engineer ‚Üí QA Engineer
   ```

4. **Test parallel execution** with a moderate task:
   ```
   You: "Optimize the platform performance"

   Expected: Orchestrator ‚Üí [Frontend + Backend + RAG] in parallel
   ```

5. **Test complex multi-phase task**:
   ```
   You: "Implement the voice AI tutor feature"

   Expected: Product Manager ‚Üí UI/UX Designer ‚Üí [Backend + Frontend] parallel ‚Üí DevOps ‚Üí QA
   ```

### Future Enhancements

1. **Add specialized agents**:
   - **Data Scientist Agent**: Analyze learner engagement data, A/B testing
   - **SEO Specialist Agent**: Optimize content for search engines
   - **Security Engineer Agent**: Penetration testing, vulnerability scanning
   - **Content Creator Agent**: Generate quiz questions, summaries, exercises

2. **Implement learning from feedback**:
   - Track which agent combinations work best
   - Learn optimal execution patterns
   - Adjust agent selection based on historical success

3. **Add cost optimization**:
   - Use claude-haiku-4 for simple tasks
   - Use claude-sonnet-4-5 for moderate tasks
   - Use claude-opus-4-5 only for complex reasoning
   - Implement token budgets per agent

4. **Create agent dashboard**:
   - Real-time agent status
   - Task queue visualization
   - Performance metrics
   - Cost tracking

---

## 11. FAQ

### Q: How does the orchestrator decide which agent to use?

**A**: The orchestrator analyzes the user request to identify required domains (frontend, backend, UI, etc.) and maps them to agents using the agent_mapping in the decision algorithm. It also considers task complexity, dependencies, and historical performance.

### Q: Can I override the orchestrator's agent selection?

**A**: Yes! You can explicitly invoke a specific agent:
```
You: "Frontend Engineer, add a dark mode toggle"
```

### Q: What happens if an agent gets stuck?

**A**: Agents report blockers to the orchestrator, which can:
1. Reassign the task to a different agent
2. Request user clarification
3. Break down the task into smaller subtasks
4. Escalate to the user

### Q: How do I add a custom agent?

**A**:
1. Create a new entry in `agents/config.json`
2. Create a skill file in `/skills/your-agent/SKILL.md`
3. Define expertise, tools, and context_files
4. Test with a simple task

### Q: Can agents communicate with each other directly?

**A**: No, all communication goes through the orchestrator. This ensures:
- Central coordination
- Proper dependency management
- Quality control
- Progress tracking

### Q: Which model should I use for each agent?

**A**: Recommendations by task complexity:
- **Simple tasks** (bug fixes, small features): `claude-haiku-4` (fast, cheap)
- **Moderate tasks** (API endpoints, components): `claude-sonnet-4-5` (balanced)
- **Complex tasks** (architecture, optimization): `claude-opus-4-5` (powerful, expensive)

### Q: How do I measure orchestrator performance?

**A**: Track these metrics:
- Task completion rate
- Average delegation time
- Agent utilization
- User satisfaction scores
- Cost per task

---

## 12. Conclusion

The multi-agent orchestration system for LearnWithAvi provides a scalable, efficient way to manage complex development tasks by leveraging specialized AI agents coordinated by a central orchestrator.

**Key Benefits**:
- ‚úÖ **Faster development**: Parallel execution of independent tasks
- ‚úÖ **Higher quality**: Specialized expertise for each domain
- ‚úÖ **Better coordination**: Central orchestrator prevents conflicts
- ‚úÖ **Scalability**: Easy to add new agents as needs grow
- ‚úÖ **Cost optimization**: Use appropriate model for task complexity

**Implementation Status**:
- ‚úÖ Architecture designed
- ‚úÖ Agent specifications defined
- ‚è≥ agents/config.json needs creation
- ‚è≥ Skill files need completion
- ‚è≥ Testing and validation pending

**Next Action**: Create `agents/config.json` and test with a simple task!

---

**Document Version**: 1.0
**Last Updated**: 2026-01-16
**Author**: Orchestrator Design Team
**Status**: Ready for Implementation
